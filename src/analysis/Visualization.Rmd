---
title: "LLMs and the wisdom of small crowds"
author: "Sean Trott"
date: "October 6, 2023"
output:
  html_document:
    keep_md: yes
    toc: yes
    toc_float: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(dpi = 300, fig.format = "pdf")
```

```{r include=FALSE}
library(tidyverse)
library(lmtest)
library(forcats)
library(broom)
library(lme4)
library(ggridges)
library(lmerTest)
library(ggrepel)
library(tools)
```

# Glasgow Norms

## Load data

```{r}
### setwd("/Users/seantrott/Dropbox/UCSD/Research/NLMs/llm_clt/src/analysis/")

### Read in all data
df_all_results = read_csv("../../data/processed/gc_results.csv")
nrow(df_all_results)

### How many per list?
table(df_all_results$list_num)

### LLM data
df_llm = read_csv("../../data/processed/gc_llm_corrs.csv")
df_llm %>%
  summarise(m_spearmam = mean(spearman_llm),
            sd_spearman = sd(spearman_llm))


```

## Figure 1a

```{r}
df_individuals = df_all_results %>%
  filter(k == 1)

df_individuals %>%
  ggplot(aes(x = spearman_ppt)) +
  geom_histogram(alpha = .5) +
  labs(x="Correlation with Original Glasgow Norms", y="Count") +
  theme_minimal() +
  geom_vline(xintercept = mean(df_llm$spearman_llm), ### LLM 
              linetype = "dotted", color = "blue",
             size = 1.2, alpha = .5) +
  theme(text = element_text(size = 15))

```

## Figure 1b



```{r}

### Pivot
df_results_long = df_all_results %>%
  select('spearman_centaur1', 'spearman_centaur2', 'spearman_ppt',
         'k', 'combo_index', 'list_num') %>%
  pivot_longer(cols = c('spearman_centaur1', 'spearman_centaur2', 'spearman_ppt'),
               names_to = "sample_type",
               values_to = "correlation") %>%
  mutate(sample_type = sub("spearman_", "", sample_type)) %>%
  mutate(sample_type = ifelse(
    sample_type == "ppt", "Human", sample_type
  ))


### Visualize
df_results_summ = df_results_long %>%
  group_by(k, sample_type) %>%
  summarize(m_corr = mean(correlation),
            sd_corr = sd(correlation),
            se_corr = sd(correlation)/sqrt(n()))  %>%
  mutate(sample_type = toTitleCase(sample_type)) 

df_results_summ %>%
  ggplot(aes(x = k, y = m_corr)) +
  geom_point(aes(color=factor(sample_type), shape = factor(sample_type)), size=3, alpha = .5) +  # Add points
  geom_line(aes(color=factor(sample_type)), alpha = .6) +  # Connect points with lines
  geom_errorbar(aes(ymin=m_corr-se_corr * 2, ymax=m_corr+se_corr * 2, width=0.2, color = factor(sample_type)), alpha = .6) + 
  labs(x="Number of Participants", y="Correlation with Glasgow Norms", color = "Sample Type", shape = "Sample Type") +
  theme_minimal() +
  geom_hline(yintercept = mean(df_llm$spearman_llm), ### LLM 
              linetype = "dotted", color = "blue",
             size = 1.2, alpha = .5) +
  theme(text = element_text(size = 15),
        legend.position="bottom")

```

## Figure 1c

Here, we visualize projected differences in **quality** and **cost** of a human sample vs. GPT-4.

### Setting up cost assumptions

For human cost, we assume:

-   Rate of \$12 an hour.\
-   Approximately 5 seconds per judgment.\
-   Approximately \~720 judgments per hour.

For GPT-4 cost, we assume:

-   \$0.06 per 1000 generated tokens.
-   \$0.03 per 1000 sampled tokens.
-   Approximately 20 sampled tokens per judgment.
-   Approximately 10 generated tokens per judgment.

```{r}
### Human assumptions
RATE = 12
SECONDS_PER_JUDGMENT = 5

HUMAN_CPJ = RATE / (3600/SECONDS_PER_JUDGMENT)

### GPT-4 assumptions
COST_PER_1K_SAMPLED = 0.0003
COST_PER_1K_GENERATED = 0.0006
NUM_SAMPLED_PER_JUDGMENT = 20
NUM_GENERATED_PER_JUDGMENT = 10

GPT_CPJ = (NUM_SAMPLED_PER_JUDGMENT / 1000) * COST_PER_1K_SAMPLED + 1000 * (NUM_GENERATED_PER_JUDGMENT / 1000) * COST_PER_1K_GENERATED
```

### Visualizing


```{r}
### Visualize

df_costs_summ = df_all_results %>%
  mutate(ratio_human_quality = spearman_ppt / spearman_llm) %>%
  mutate(ratio_human_cost = (k * HUMAN_CPJ) / GPT_CPJ) %>%
  mutate(ratio_centaur1_quality = spearman_centaur1 / spearman_llm) %>%
  mutate(ratio_centaur1_cost = (GPT_CPJ + k * HUMAN_CPJ) / GPT_CPJ) %>%
  mutate(ratio_centaur2_quality = spearman_centaur2 / spearman_llm) %>%
  mutate(ratio_centaur2_cost = (GPT_CPJ + k * HUMAN_CPJ) / GPT_CPJ) %>%
  group_by(k) %>%
  summarise(m_human_ratio_quality = mean(ratio_human_quality),
            se_human_ratio_quality = sd(ratio_human_quality)/sqrt(n()),
            m_human_ratio_cost = mean(ratio_human_cost),
            se_human_ratio_cost = sd(ratio_human_cost),
            ### Centaur1
            m_centaur1_ratio_quality = mean(ratio_centaur1_quality),
            se_centaur1_ratio_quality = sd(ratio_centaur1_quality)/sqrt(n()),
            m_centaur1_ratio_cost = mean(ratio_centaur1_cost),
            se_centaur1_ratio_cost = sd(ratio_centaur1_cost),
            ### Centaur2
            m_centaur2_ratio_quality = mean(ratio_centaur2_quality),
            se_centaur2_ratio_quality = sd(ratio_centaur2_quality)/sqrt(n()),
            m_centaur2_ratio_cost = mean(ratio_centaur2_cost),
            se_centaur2_ratio_cost = sd(ratio_centaur2_cost))

df_costs_summ_long <- df_costs_summ %>%
  pivot_longer(
    cols = -k,
    names_to = "variable",
    values_to = "value"
  ) %>%
  mutate(
    sample_type = str_extract(variable, "human|centaur1|centaur2"),
    metric = case_when(
      str_detect(variable, "m_.*_quality") ~ "m_quality",
      str_detect(variable, "se_.*_quality") ~ "se_quality",
      str_detect(variable, "m_.*_cost") ~ "m_cost",
      str_detect(variable, "se_.*_cost") ~ "se_cost"
    )
  ) %>%
  select(-variable) %>%
  pivot_wider(
    names_from = metric,
    values_from = value
  ) %>%
  mutate(sample_type = toTitleCase(sample_type))

df_costs_summ_long %>%
  ggplot(aes(x = m_quality, y = m_cost, color = sample_type, shape = sample_type)) +
  geom_point(size=3, alpha = .5) +  # Add points
  geom_line(alpha = .6) +  # Connect points with lines
  labs(x="Quality Ratio", y="Cost Ratio",
       color = "Sample Type", shape = "Sample Type") +
  theme_minimal() +
  geom_vline(xintercept = 1, linetype = "dotted") +
  theme(text = element_text(size = 15),
        legend.position="bottom") 
```

# RAW-C Norms

## Load data

```{r}
### Read in all data
df_all_results = read_csv("../../data/processed/rawc_results.csv")
nrow(df_all_results)

### How many per list?
table(df_all_results$list_num)

### LLM data
df_llm = read_csv("../../data/processed/rawc_llm_corrs.csv")
df_llm %>%
  summarise(m_spearmam = mean(spearman_llm),
            sd_spearman = sd(spearman_llm))


```

## Figure 1a

```{r}
df_individuals = df_all_results %>%
  filter(k == 1)

mean(df_individuals$spearman_ppt)
sd(df_individuals$spearman_ppt)
df_individuals %>%
  ggplot(aes(x = spearman_ppt)) +
  geom_histogram(alpha = .5) +
  labs(x="Correlation with Original RAW-C Norms", y="Count") +
  theme_minimal() +
  geom_vline(xintercept = mean(df_llm$spearman_llm), ### LLM 
              linetype = "dotted", color = "blue",
             size = 1.2, alpha = .5) +
  theme(text = element_text(size = 15))

```

## Figure 1b

```{r}
### Pivot
df_results_long = df_all_results %>%
  select('spearman_centaur1', 'spearman_centaur2', 'spearman_ppt',
         'k', 'combo_index', 'list_num') %>%
  pivot_longer(cols = c('spearman_centaur1', 'spearman_centaur2', 'spearman_ppt'),
               names_to = "sample_type",
               values_to = "correlation") %>%
  mutate(sample_type = sub("spearman_", "", sample_type)) %>%
  mutate(sample_type = ifelse(
    sample_type == "ppt", "Human", sample_type
  ))


### Visualize
df_results_summ = df_results_long %>%
  group_by(k, sample_type) %>%
  summarize(m_corr = mean(correlation),
            sd_corr = sd(correlation),
            se_corr = sd(correlation)/sqrt(n()))  %>%
  mutate(sample_type = toTitleCase(sample_type)) 

df_results_summ %>%
  ggplot(aes(x = k, y = m_corr)) +
  geom_point(aes(color=factor(sample_type),shape = factor(sample_type)), size =3, alpha = .6) +  # Add points
  geom_line(aes(color=factor(sample_type)), alpha = .5) +  # Connect points with lines
  geom_errorbar(aes(ymin=m_corr-se_corr * 2, ymax=m_corr+se_corr * 2, width=0.2, color = factor(sample_type)), alpha = .5) + 
  labs(x="Number of Participants", y="Spearman's Rho", color = "Sample Type",
       shape = "Sample Type") +
  theme_minimal() +
  geom_hline(yintercept = mean(df_llm$spearman_llm), ### LLM 
              linetype = "dotted", color = "blue",
             size = 1.2, alpha = .5) +
  theme(text = element_text(size = 15),
        legend.position="bottom")


```

## Figure 1c

### Setting up cost assumptions

For human cost, we assume:

-   Rate of \$12 an hour.\
-   Approximately 5 seconds per judgment.\
-   Approximately \~720 judgments per hour.

For GPT-4 cost, we assume:

-   \$0.06 per 1000 generated tokens.
-   \$0.03 per 1000 sampled tokens.
-   Approximately 20 sampled tokens per judgment.
-   Approximately 10 generated tokens per judgment.

```{r}
### Human assumptions
RATE = 12
SECONDS_PER_JUDGMENT = 5

HUMAN_CPJ = RATE / (3600/SECONDS_PER_JUDGMENT)

### GPT-4 assumptions
COST_PER_1K_SAMPLED = 0.0003
COST_PER_1K_GENERATED = 0.0006
NUM_SAMPLED_PER_JUDGMENT = 20
NUM_GENERATED_PER_JUDGMENT = 10

GPT_CPJ = (NUM_SAMPLED_PER_JUDGMENT / 1000) * COST_PER_1K_SAMPLED + 1000 * (NUM_GENERATED_PER_JUDGMENT / 1000) * COST_PER_1K_GENERATED
```

### Visualizing


```{r}
### Visualize

df_costs_summ = df_all_results %>%
  mutate(ratio_human_quality = spearman_ppt / spearman_llm) %>%
  mutate(ratio_human_cost = (k * HUMAN_CPJ) / GPT_CPJ) %>%
  mutate(ratio_centaur1_quality = spearman_centaur1 / spearman_llm) %>%
  mutate(ratio_centaur1_cost = (GPT_CPJ + k * HUMAN_CPJ) / GPT_CPJ) %>%
  mutate(ratio_centaur2_quality = spearman_centaur2 / spearman_llm) %>%
  mutate(ratio_centaur2_cost = (GPT_CPJ + k * HUMAN_CPJ) / GPT_CPJ) %>%
  group_by(k) %>%
  summarise(m_human_ratio_quality = mean(ratio_human_quality),
            se_human_ratio_quality = sd(ratio_human_quality)/sqrt(n()),
            m_human_ratio_cost = mean(ratio_human_cost),
            se_human_ratio_cost = sd(ratio_human_cost),
            ### Centaur1
            m_centaur1_ratio_quality = mean(ratio_centaur1_quality),
            se_centaur1_ratio_quality = sd(ratio_centaur1_quality)/sqrt(n()),
            m_centaur1_ratio_cost = mean(ratio_centaur1_cost),
            se_centaur1_ratio_cost = sd(ratio_centaur1_cost),
            ### Centaur2
            m_centaur2_ratio_quality = mean(ratio_centaur2_quality),
            se_centaur2_ratio_quality = sd(ratio_centaur2_quality)/sqrt(n()),
            m_centaur2_ratio_cost = mean(ratio_centaur2_cost),
            se_centaur2_ratio_cost = sd(ratio_centaur2_cost))

df_costs_summ_long <- df_costs_summ %>%
  pivot_longer(
    cols = -k,
    names_to = "variable",
    values_to = "value"
  ) %>%
  mutate(
    sample_type = str_extract(variable, "human|centaur1|centaur2"),
    metric = case_when(
      str_detect(variable, "m_.*_quality") ~ "m_quality",
      str_detect(variable, "se_.*_quality") ~ "se_quality",
      str_detect(variable, "m_.*_cost") ~ "m_cost",
      str_detect(variable, "se_.*_cost") ~ "se_cost"
    )
  ) %>%
  select(-variable) %>%
  pivot_wider(
    names_from = metric,
    values_from = value
  ) %>%
  mutate(sample_type = toTitleCase(sample_type))

df_costs_summ_long %>%
  ggplot(aes(x = m_quality, y = m_cost, color = sample_type, shape = sample_type)) +
  geom_point(size=3, alpha = .5) +  # Add points
  geom_line(alpha = .6) +  # Connect points with lines
  # geom_smooth(alpha = .2) +
  labs(x="Quality Ratio", y="Cost Ratio",
       color = "Sample Type", shape = "Sample Type") +
  theme_minimal() +
  geom_vline(xintercept = 1, linetype = "dotted") +
  theme(text = element_text(size = 15),
        legend.position="bottom") 
```


